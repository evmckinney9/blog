{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Measuring Puzzle Complexity: Part 1\"\n",
    "> \"A look at how sudoku generating algorithms consider their own difficulty level\"\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [puzzles, python]\n",
    "- image: images/thumbnails/puzzle_1.jpg\n",
    "- author: Evan McKinney\n",
    "- published: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were to program a video game bot for your players to compete against, how might your bots be programmed with varying difficulty settings? I think this is an interesting question because when I think about programming algorithms, it is usually from the perspective of being correct on all possible inputs - rather than having varying degrees of success {% fn 1 %}. Despite my inexperience with game development (or any game theory), because I know this question must have been well researched for decades, I'm hoping some exploration can be enlightening.\n",
    "\n",
    "Complex games allow for many compounding behaviors to be adjusted, and therefore, the more simple the game is, I believe it is less clear how to discriminate difficulty levels between, say, purely random and perfect knowledge bots. For example, in a shooter video game, besides properties such as enemies with higher health or more powerful weapons, you might decide that stronger bots can aim more quickly, pinpoint your location faster, can stategically retreat on higher health thresholds, or more regularly coordinate attacks, and so on. In constrast, consider for the simple game of Connect-4, what would a medium difficulty level algorithm look like? Its less clear now because instead of scaling various enemy attributes, the opponent returns only a single value representing a column. \n",
    "\n",
    "First, you might calculate how good every possible move is, and then make a move accordingly, but brute force is often not a good algorithm choice. A second way I imagine doing this is to program an ideal player, and lower skilled bots would tend to make mistakes more often, i.e. place their chip 1-2 spaces away from the ideal location with varying frequencies. I think this is also a poor choice because fails to differentiate between easy and hard to find moves; meaning that a human should recognize the best move when it protects from an immediate loss more often than recognizing the best move when chips are sparsely placed in the early game. Finally, you might just program completely different algorithm, and play against them to determine their relative abilities, not unlike an ELO score. It would be nice to know ahead of time what strategies correlate to skill level and to program that in your separate bots. I could read a strategy guide and program the beginner method - knowing the best starting position and response to basic shapes like 'L's or 'T's. I read the next chapter in the strategy guide and program the medium bot- which now knows more shape strategies and has a small look ahead. And finally the expert bot - which refuses to lose by using the mathematician's computed perfect strategy {% fn 2 %}.\n",
    "\n",
    "This question regarding programming lower-skilled computer game opponents is something that I hope to explore in this blog post, in particular, when the computer opponent is considered to be the procedural generation of a sudoku puzzle. What makes a procedurally generated sudoku easy or hard? How to reverse engineer a sudokus difficulty/ What quantities a sudokus difficulty/procedure vs handcrafted\n",
    "\n",
    "Chess ELOs - chess.com has bots which mimic not only ELO but playstyles quantifying based results, how long it took a human to solve, how difficult techniques I needed to use.\n",
    "\n",
    "{{ 'A good counterexample is k-approximation algorithms. For hard problems, in particular NP-hard, a k-approximation algorthim guarantees it is no more than k-times worse than the optimal solution. You might imagine that an easy-mode is thus a 5-approximation, medium-mode is a 4-approximation, hard-mode is a 3-approximation, and so on. For some examples, like Chess or Connect-4, I think this framing is relevant because you could define an optimal strategy in terms of minimizing the number of turns until a forced victory. However, for Sudoku generation, I don't think it makes sense to talk about an optimum in the same way.| fndetail: 1 }}\n",
    "\n",
    "{{ '[A Knowledge-based Approach of Connect-Four](http://www.informatik.uni-trier.de/~fernau/DSL0607/Masterthesis-Viergewinnt.pdf)!' | fndetail: 2 }}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant Videos:\n",
    "> youtube: https://www.youtube.com/watch?v=U4ogK0MIzqk\n",
    "\n",
    "> youtube: https://www.youtube.com/watch?v=DpXy041BIlA&t=144s"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "addfc48ccfa42a606ba32bfef47b227f1f304d22e73cf1873752ac375fdb2846"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
